{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3. Embedding word2vec fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import annoy\n",
    "import numpy as np\n",
    "import gensim.models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание на поиск похожих по эмбеддингам\n",
    "\n",
    "1. Объединить в одну выборку\n",
    "\n",
    "2. На основе word2vec/fasttext/русскоязычная модель rusvectors/слоя Embedding реализовать метод поиска ближайших твитов:\n",
    "\n",
    "-- на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, \n",
    "\n",
    "-- метод должен возвращать 5-ть ближайших твитов к этому запросу\n",
    "\n",
    "3. Проверить насколько хорошо работают подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План решения\n",
    "\n",
    "[0. Загрузка и просмотр данных](#section_0)\n",
    "\n",
    "[1. Функции и процедуры подготовки данных](#section_1)\n",
    "\n",
    "[2. Методs поиска ближайших твитов](#section_2)\n",
    "\n",
    "[2.1. Word2vec](#section_2.1)\n",
    "\n",
    "[2.2. Fasttext](#section_2.2)\n",
    "\n",
    "[2.3. Русскоязычная модель ruwikiruscorpora_upos_cbow_300_10_2021](#section_2.3)\n",
    "\n",
    "[2.4. Embedding слой](#section_2.4)\n",
    "\n",
    "[3. Оценки работы моделей](#section_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Загрузка и просмотр данных <a id='section_0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и объединим их в один датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  @first_timee хоть я и школота, но поверь, у на...  positive\n",
       "1  Да, все-таки он немного похож на него. Но мой ...  positive\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...  positive\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...  positive\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...  positive"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive(2).csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "\n",
    "negative = pd.read_csv('negative(2).csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "\n",
    "df = positive.append(negative)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем данные на train и test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Функции и процедуры подготовки данных <a id='section_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Функция преобразования твита (лемматизация, удаление стоп-слов и пунктуации)\n",
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firsttimee',\n",
       " 'школотый',\n",
       " 'поверь',\n",
       " 'самый',\n",
       " 'd',\n",
       " 'общество',\n",
       " 'профилировать',\n",
       " 'предмет',\n",
       " 'тип']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример обработки твита\n",
    "preprocess_txt(df['text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Процедура подготовки данных к обучению (создание списка токенов для каждого твита)\n",
    "assert True\n",
    "\n",
    "# Preprocess for models fitting\n",
    "tweet_tokens = []\n",
    "c = 0\n",
    "for text in x_train:\n",
    "    tweet_prep = preprocess_txt(text)\n",
    "    tweet_tokens.append(tweet_prep)\n",
    "    c += 1\n",
    "    if c > 100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лёша',\n",
       " 'лазарев',\n",
       " '—',\n",
       " 'чокнутый',\n",
       " 'парень',\n",
       " 'd',\n",
       " 'надеяться',\n",
       " 'будущее',\n",
       " 'друг',\n",
       " 'httptcoa1ngw1zhzk']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подготовленные токены твитов (для x_train)\n",
    "tweet_tokens = [i for i in tweet_tokens if len(i) > 2]\n",
    "tweet_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Функция поиска 5 ближайших твитов\n",
    "def get_response(tweet, index, model, index_map):\n",
    "    tweet_token = preprocess_txt(tweet)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    for word in tweet_token:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    similar_tweet = index.get_nns_by_vector(vector, 5, include_distances=True)\n",
    "    \n",
    "    result = pd.DataFrame({'tweet': [index_map[i]  for i in similar_tweet[0]], \n",
    "                           'distance' : similar_tweet[1]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Методы поиска ближайших твитов <a id='section_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Процедура поиска ближайших твитов\n",
    "def get_model_index(model):\n",
    "    model_index = annoy.AnnoyIndex(300 ,'angular') # поиск ближайших соседей\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "\n",
    "    for tweet in x_train:\n",
    "        n_model = 0\n",
    "        index_map[counter] = tweet\n",
    "        tweet_prep = preprocess_txt(tweet)\n",
    "        \n",
    "        vector_model = np.zeros(300) #вектор твита\n",
    "\n",
    "        for word in tweet_prep:\n",
    "            if word in model:\n",
    "                vector_model += model[word]\n",
    "                n_model += 1\n",
    "        if n_model > 0:\n",
    "            vector_model = vector_model / n_model #нормализуем вектор твита\n",
    "       \n",
    "        model_index.add_item(counter, vector_model) #добавляем элемент для индексации\n",
    "     \n",
    "        counter += 1\n",
    "\n",
    "        if counter > 100000:\n",
    "            break\n",
    "\n",
    "    model_index.build(10) #из индексов создаем лес из 10 деревьев\n",
    "    return model_index, index_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Word2wec <a id='section_2.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=tweet_tokens, vector_size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_index, index_map = get_model_index(modelW2V.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Крапаю введение для диплома. Пишется пока хреново. Ну не умею я длинно писать. :(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@DiKazantseva спасибо Диан , просто оч неприят...</td>\n",
       "      <td>0.008853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@_Nothing_Good_ ага, там еще и не такое писали(</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KattyMorton она всегда заранее пишет варианты...</td>\n",
       "      <td>0.010095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.12.13 дадада, ты опять скажешь, что я фигню ...</td>\n",
       "      <td>0.010197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>С питерского жопореза писал на ЛОР с забаненно...</td>\n",
       "      <td>0.010514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  distance\n",
       "0  @DiKazantseva спасибо Диан , просто оч неприят...  0.008853\n",
       "1    @_Nothing_Good_ ага, там еще и не такое писали(  0.009642\n",
       "2  @KattyMorton она всегда заранее пишет варианты...  0.010095\n",
       "3  9.12.13 дадада, ты опять скажешь, что я фигню ...  0.010197\n",
       "4  С питерского жопореза писал на ЛОР с забаненно...  0.010514"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.values[0])\n",
    "get_response(x_test.values[0], w2v_index, modelW2V.wv, index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Fasttext <a id='section_2.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=tweet_tokens, vector_size=300, min_count=1, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_index, index_map = get_model_index(modelFT.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Крапаю введение для диплома. Пишется пока хреново. Ну не умею я длинно писать. :(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вот не знала не знала, что от спорта может быт...</td>\n",
       "      <td>0.024794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Глупо, когда говорят \"прощают / слабые\" / Я не...</td>\n",
       "      <td>0.030293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@innamango ты просто написала типо кто не зага...</td>\n",
       "      <td>0.032466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>вот я одна сегодня даже и не думала загадывать...</td>\n",
       "      <td>0.032578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@NShtembulska это чтобы тебя не раздражать, за...</td>\n",
       "      <td>0.032684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  distance\n",
       "0  Вот не знала не знала, что от спорта может быт...  0.024794\n",
       "1  Глупо, когда говорят \"прощают / слабые\" / Я не...  0.030293\n",
       "2  @innamango ты просто написала типо кто не зага...  0.032466\n",
       "3  вот я одна сегодня даже и не думала загадывать...  0.032578\n",
       "4  @NShtembulska это чтобы тебя не раздражать, за...  0.032684"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.values[0])\n",
    "get_response(x_test.values[0], ft_index, modelFT.wv, index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Русскоязычная модель ruwikiruscorpora_upos_cbow_300_10_2021  <a id='section_2.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGLoVE = gensim.models.KeyedVectors.load_word2vec_format('./glove/model.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_index, index_map = get_model_index(modelGLoVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Крапаю введение для диплома. Пишется пока хреново. Ну не умею я длинно писать. :(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Бляяя 9 дней подряд вставать в 6:20..капецц\\nс...</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ВСЁ ТАКИ ОТТЯНУТ СИМОНА((\\nПУСТЬ ХОТЯ БЫ ИЗ 10...</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>на Гарри Поттере, моего кота зовут Волан-де-мо...</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Farewell_Finn аааа!)) я тоже)) особенно тех, ...</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Dashagagaloo ой бля не сыпь мне соль на рану(...</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  distance\n",
       "0  Бляяя 9 дней подряд вставать в 6:20..капецц\\nс...  1.414214\n",
       "1  ВСЁ ТАКИ ОТТЯНУТ СИМОНА((\\nПУСТЬ ХОТЯ БЫ ИЗ 10...  1.414214\n",
       "2  на Гарри Поттере, моего кота зовут Волан-де-мо...  1.414214\n",
       "3  @Farewell_Finn аааа!)) я тоже)) особенно тех, ...  1.414214\n",
       "4  @Dashagagaloo ой бля не сыпь мне соль на рану(...  1.414214"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.values[0])\n",
    "get_response(x_test.values[0], glove_index,modelGLoVE, index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Embedding слой  <a id='section_2.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([x for l in tweet_tokens for x in l]) #список всех токенов из x_train\n",
    "#создание слоя словаря\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=100000,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1)\n",
    "#создаем словарь\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "\n",
    "#создаем модель\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string)) #на вход подается строка\n",
    "model.add(vectorize_layer)  #получаем тензор (1, 100), содержащий для каждого слова индексы из словаря \n",
    "model.add(Embedding(100000, 300, input_length=100, mask_zero=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отучил поляка от лола, установил ему доту и вот он сидит с ботами играет, учится) красота\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013F0E923310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.51896025e-02,  1.93531998e-02,  7.84177706e-03,  1.72587372e-02,\n",
       "         3.50482948e-02,  2.76690386e-02,  8.73645395e-03, -2.88944840e-02,\n",
       "         3.05211656e-02,  3.56670134e-02, -3.27259786e-02, -2.52324939e-02,\n",
       "         1.01154931e-02, -4.65058088e-02,  4.42801975e-02, -4.62143496e-03,\n",
       "         1.76946260e-02,  3.83440368e-02, -1.16466172e-02,  2.22341754e-02,\n",
       "        -5.50440699e-03, -3.80901247e-03, -3.13960016e-04, -1.70698278e-02,\n",
       "         1.18994340e-02, -4.18061242e-02,  4.54228409e-02, -3.41743119e-02,\n",
       "         3.83315198e-02,  1.96713693e-02, -3.11342832e-02,  9.48014110e-03,\n",
       "        -5.36371022e-04,  2.68412344e-02, -2.91655418e-02,  2.46965401e-02,\n",
       "         2.82076709e-02,  2.36405060e-03,  2.49383338e-02,  2.59997696e-03,\n",
       "        -1.83482766e-02, -2.56215222e-02, -2.98489090e-02,  1.64824836e-02,\n",
       "         2.49980725e-02, -2.36342084e-02, -2.98985839e-02, -4.67239283e-02,\n",
       "         5.17304987e-03,  3.42441313e-02, -1.65807717e-02, -3.26831266e-03,\n",
       "         2.95661390e-04, -7.88235664e-03, -3.33362371e-02,  2.74340995e-02,\n",
       "         4.29194085e-02,  5.05246967e-03,  4.47318815e-02, -1.69599280e-02,\n",
       "        -3.86105068e-02, -3.81040797e-02,  1.81639083e-02, -1.64125077e-02,\n",
       "         2.66517662e-02,  2.79310234e-02, -1.24927759e-02,  4.46461327e-02,\n",
       "         8.30473751e-03,  3.32063437e-03, -3.19239721e-02, -2.12088116e-02,\n",
       "        -3.89339812e-02, -2.72709485e-02, -1.31165981e-02,  2.55617015e-02,\n",
       "        -2.42739320e-02, -3.06580309e-02,  2.39040889e-02,  4.68408950e-02,\n",
       "         2.11035348e-02,  2.38851942e-02,  1.47497989e-02,  2.42856257e-02,\n",
       "        -3.27581055e-02,  1.31821893e-02, -2.02499386e-02,  6.14644215e-03,\n",
       "        -4.85495925e-02, -4.33013551e-02,  4.62021716e-02, -2.90025007e-02,\n",
       "         3.12261246e-02,  2.78296359e-02,  2.58827545e-02,  2.61571519e-02,\n",
       "         6.98474795e-03,  3.83620337e-03, -1.21651292e-02, -3.94888744e-02,\n",
       "         1.05674379e-02,  2.78509147e-02,  4.34307717e-02,  5.95299155e-03,\n",
       "         2.33299471e-02, -1.47862434e-02,  4.97247092e-02, -5.33193350e-03,\n",
       "        -3.40676084e-02, -9.94763523e-03,  2.62704976e-02,  1.18732452e-02,\n",
       "         9.94846970e-03, -4.48006876e-02,  1.34580620e-02, -2.16889139e-02,\n",
       "         4.28719409e-02,  4.65660170e-03,  3.42855193e-02, -4.77770716e-03,\n",
       "        -4.61576134e-03,  2.40048282e-02,  4.86961752e-03,  6.22414052e-04,\n",
       "         2.76735090e-02, -2.75298115e-02, -1.53137669e-02, -3.80379669e-02,\n",
       "        -3.89317498e-02,  5.44376299e-03, -1.12690702e-02, -2.70217191e-02,\n",
       "        -4.20346744e-02,  2.49545686e-02,  1.79408230e-02, -3.24287638e-02,\n",
       "        -5.05067036e-03, -3.85892875e-02,  2.74373628e-02, -1.96114909e-02,\n",
       "         2.99068950e-02, -4.65564728e-02, -5.75075299e-03, -4.72580306e-02,\n",
       "         4.43732180e-02, -3.89396437e-02,  2.61719152e-03, -3.17893177e-02,\n",
       "        -1.98585037e-02,  4.54476140e-02, -4.12649997e-02,  4.57066409e-02,\n",
       "         2.53552832e-02,  1.45920031e-02,  3.81364115e-02,  2.79612057e-02,\n",
       "         1.26210563e-02,  3.18167843e-02, -4.96800058e-02, -1.35507695e-02,\n",
       "         2.71733068e-02, -2.26301551e-02,  6.70697540e-03,  2.53667347e-02,\n",
       "        -4.96500246e-02,  2.34028809e-02,  3.31455469e-03,  6.59750775e-03,\n",
       "         8.97308439e-03,  3.17498296e-03, -3.30707654e-02, -2.38549598e-02,\n",
       "        -3.23115811e-02, -1.80173628e-02, -4.95637320e-02, -4.09951098e-02,\n",
       "         3.09834145e-02, -3.77964750e-02, -1.45950094e-02, -3.49701531e-02,\n",
       "        -3.94016877e-02,  2.73145176e-02,  4.89719994e-02, -4.69240062e-02,\n",
       "        -3.72947231e-02, -2.73908302e-03,  3.14240344e-02, -8.15039873e-03,\n",
       "         4.14651074e-02, -2.05394980e-02, -4.99198325e-02, -2.67157312e-02,\n",
       "        -3.11043113e-03,  3.47848646e-02,  4.02525105e-02,  5.22136688e-05,\n",
       "        -2.60625724e-02, -1.09539516e-02, -1.93729158e-02, -3.35645825e-02,\n",
       "         4.18070592e-02,  4.36465032e-02,  1.21676102e-02, -3.97161245e-02,\n",
       "        -6.66268170e-05, -4.39108126e-02, -3.97896282e-02,  1.52842067e-02,\n",
       "        -1.60670765e-02,  5.79122454e-03,  3.77120487e-02,  2.40601785e-02,\n",
       "         3.72855701e-02,  6.40257448e-03, -7.29160383e-03, -3.16056758e-02,\n",
       "        -1.02807395e-02,  1.26893446e-03,  7.80924410e-03,  4.36583422e-02,\n",
       "         1.02650635e-02,  1.92567222e-02,  4.54120152e-02, -6.41644001e-04,\n",
       "        -4.72100377e-02,  4.55315970e-02, -1.72925703e-02,  2.49334238e-02,\n",
       "        -1.16080046e-03, -4.78055365e-02,  2.53092758e-02, -2.57696640e-02,\n",
       "        -3.18194628e-02, -1.69155747e-03,  2.73580216e-02,  4.08288091e-03,\n",
       "         2.57286541e-02, -4.58812974e-02,  4.45694588e-02, -2.98472047e-02,\n",
       "         3.53841446e-02,  3.01402099e-02,  4.52331044e-02, -2.06329357e-02,\n",
       "         4.36943769e-03, -2.57809088e-03,  4.16542627e-02,  3.89630683e-02,\n",
       "         2.75242589e-02, -2.91526075e-02,  2.19260715e-02,  1.71638392e-02,\n",
       "         3.48428600e-02,  1.04167685e-02,  4.93702404e-02, -3.36043388e-02,\n",
       "        -9.35487822e-03,  3.33078392e-02,  2.91209556e-02,  1.59665085e-02,\n",
       "         4.56518047e-02, -1.09775439e-02,  2.17868946e-02, -1.17383003e-02,\n",
       "         4.60793413e-02, -2.91372463e-03, -2.05429792e-02,  5.96338511e-03,\n",
       "         1.85011663e-02,  2.31997408e-02,  4.52093370e-02, -2.37585194e-02,\n",
       "         6.65146112e-03,  3.74967568e-02,  2.18629874e-02,  5.14952093e-03,\n",
       "        -1.80541500e-02, -6.97980076e-03,  2.40385421e-02,  5.88465482e-04,\n",
       "         1.81469806e-02, -3.73568386e-03,  1.48715116e-02, -3.80276442e-02,\n",
       "        -2.37685442e-03, -3.37739736e-02,  3.78080346e-02,  2.36098841e-03,\n",
       "        -3.52996476e-02, -3.43100801e-02, -3.73747200e-03, -4.97123003e-02,\n",
       "         7.81490654e-03, -3.55604403e-02,  2.90705599e-02,  2.87396573e-02,\n",
       "         1.06832273e-02, -5.87760285e-03, -4.08770442e-02,  7.61790201e-03],\n",
       "       dtype=float32),\n",
       " (300,))"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.values[0])\n",
    "v1 = model.predict([x_test.values[0]])[0][0]\n",
    "v2 = model.predict([x_test.values[1]])[0][0]\n",
    "v1, v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Процедура поиска ближайших твитов\n",
    "emb_index = annoy.AnnoyIndex(300 ,'angular') # поиск ближайших соседей\n",
    "\n",
    "emb_map = {}\n",
    "counter = 0\n",
    "\n",
    "for tweet in x_train:\n",
    "    emb_map[counter] = tweet\n",
    "    vector_emb = model.predict([tweet])[0][0]\n",
    "    emb_index.add_item(counter, vector_emb) #добавляем элемент для индексации\n",
    "    counter += 1\n",
    "        \n",
    "    if counter > 100000:\n",
    "        break\n",
    "\n",
    "emb_index.build(10) #из индексов создаем лес из 10 деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_emb(model, emb_index, tweet, n_similar_tweets):\n",
    "    vector = model.predict([tweet])[0][0]\n",
    "\n",
    "    similar_tweet = emb_index.get_nns_by_vector(vector, n_similar_tweets, include_distances=True)\n",
    "    \n",
    "    result = pd.DataFrame({'tweet': [emb_map[i]  for i in similar_tweet[0]], \n",
    "                           'distance' : similar_tweet[1]\n",
    "                          })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отучил поляка от лола, установил ему доту и вот он сидит с ботами играет, учится) красота\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>не знаю какой фильм посмотреть( уже 4ый начала...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как же я скучаю по твоему \"канешно\"мне етого н...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>О, Билл! И тебе приветики :D http://t.co/n5cjP...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Череповце сегодня каток на улицах. Вчера рас...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Пришлось у мамы Ноут забрать, я так и не смог ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  distance\n",
       "0  не знаю какой фильм посмотреть( уже 4ый начала...       0.0\n",
       "1  Как же я скучаю по твоему \"канешно\"мне етого н...       0.0\n",
       "2  О, Билл! И тебе приветики :D http://t.co/n5cjP...       0.0\n",
       "3  В Череповце сегодня каток на улицах. Вчера рас...       0.0\n",
       "4  Пришлось у мамы Ноут забрать, я так и не смог ...       0.0"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.values[0])\n",
    "get_response_emb(model, emb_index, x_test.values[0], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Оценки работы моделей <a id='section_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** наиболее близкие твиты ищет модель Word2wec. У русскоязычной модели ruwikiruscorpora_upos_cbow_300_10_2021 и Embwdding слоя проблемы с подсчетом дистации (пока решить не удалось)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P.S.** Если подскажите в чем ошибка кода, буду благодарна :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
